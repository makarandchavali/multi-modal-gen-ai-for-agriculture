{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9dff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jjj\\anaconda\\lib\\site-packages (2.4.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.20.0-cp39-cp39-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\jjj\\anaconda\\lib\\site-packages (4.43.4)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.0-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jjj\\anaconda\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\jjj\\anaconda\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jjj\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Using cached torchvision-0.20.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "Downloading torch-2.5.0-cp39-cp39-win_amd64.whl (203.0 MB)\n",
      "   -------------                            67.1/203.0 MB ? eta -:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\http\\client.py\", line 463, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\http\\client.py\", line 507, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 379, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\jjj\\anaconda\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\", ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d13dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the data\n",
    "data = [\n",
    "    [\"train/Apple rust leaf/Apple rust leaf (1).jpg\", \"Apple Rust Leaf\", \"Yellow-orange spots, premature leaf fall\", \"Use fungicide containing myclobutanil\"],\n",
    "    [\"train/Bell_pepper leaf spot/Bell_pepper leaf (1).jpg\", \"Bell Pepper Leaf Spot\", \"Dark, water-soaked spots on leaves\", \"Apply copper-based fungicide\"],\n",
    "    [\"train/Corn rust leaf/Corn rust leaf (1).jpg\", \"Corn Rust Leaf\", \"Reddish-brown pustules, leaf wilting\", \"Use resistant corn varieties and fungicides\"]\n",
    "]\n",
    "\n",
    "# Create the CSV file\n",
    "with open('plant_diseases.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"filename\", \"disease_name\", \"symptoms\", \"treatment\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6341089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease: Bell Pepper Leaf Spot\n",
      "Symptoms: Dark, water-soaked spots on leaves\n",
      "Treatment: Apply copper-based fungicide\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize CLIP model and processor\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Define paths and load sample data\n",
    "dataset_path = \"./dataset/train\"\n",
    "disease_directories = [\"Apple rust leaf\", \"Bell_pepper leaf spot\", \"Corn rust leaf\"]\n",
    "\n",
    "# Create annotations for sample purposes (replace with actual data if available)\n",
    "annotations = [\n",
    "    {\n",
    "        \"filename\": \"Apple rust leaf/Apple rust leaf (1).jpg\",\n",
    "        \"disease\": \"Apple Rust Leaf\",\n",
    "        \"symptoms\": \"Yellow-orange spots, premature leaf fall\",\n",
    "        \"treatment\": \"Use fungicide containing myclobutanil\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"Bell_pepper leaf spot//Bell_pepper leaf (1).jpg\",\n",
    "        \"disease\": \"Bell Pepper Leaf Spot\",\n",
    "        \"symptoms\": \"Dark, water-soaked spots on leaves\",\n",
    "        \"treatment\": \"Apply copper-based fungicide\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"Corn rust leaf/Corn rust leaf (1).jpg\",\n",
    "        \"disease\": \"Corn Rust Leaf\",\n",
    "        \"symptoms\": \"Reddish-brown pustules, leaf wilting\",\n",
    "        \"treatment\": \"Use resistant corn varieties and fungicides\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to encode images using CLIP\n",
    "def encode_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "    return image_features\n",
    "\n",
    "# Function to encode text using CLIP\n",
    "def encode_text(text):\n",
    "    inputs = processor(text=text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**inputs)\n",
    "    return text_features\n",
    "\n",
    "# Function to match user query and provide a response\n",
    "def get_disease_info(image_path, query):\n",
    "    image_features = encode_image(image_path)\n",
    "    text_features = encode_text(query)\n",
    "\n",
    "    # Simulate matching process\n",
    "    highest_similarity = float('-inf')\n",
    "    best_match = None\n",
    "\n",
    "    for annotation in annotations:\n",
    "        disease_text = f\"{annotation['disease']}: {annotation['symptoms']}\"\n",
    "        disease_features = encode_text(disease_text)\n",
    "\n",
    "        # Cosine similarity\n",
    "        similarity = torch.nn.functional.cosine_similarity(text_features, disease_features, dim=1).item()\n",
    "\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            best_match = annotation\n",
    "\n",
    "    # Provide response based on the best match\n",
    "    if best_match:\n",
    "        print(f\"Disease: {best_match['disease']}\")\n",
    "        print(f\"Symptoms: {best_match['symptoms']}\")\n",
    "        print(f\"Treatment: {best_match['treatment']}\")\n",
    "    else:\n",
    "        print(\"No relevant information found.\")\n",
    "\n",
    "# Example usage\n",
    "image_path = \"./PlantDoc-Dataset/train/Apple rust leaf/Apple rust leaf (2).jpg\"\n",
    "user_query = \"How to treat yellowing leaves on my plant?\"\n",
    "get_disease_info(image_path, user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba8468c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaef642f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jjj\\anaconda\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jjj\\anaconda\\lib\\site-packages (0.20.0)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.0-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jjj\\anaconda\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Downloading torchaudio-2.5.0-cp39-cp39-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 2.4/2.4 MB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f1411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.6213\n",
      "Epoch [2/2], Loss: 1.1660\n",
      "CNN Prediction: Apple rust leaf\n",
      "Symptoms: Yellow-orange spots, premature leaf fall\n",
      "Treatment: Use fungicide containing myclobutanil\n",
      "CLIP Similarity with Query: 0.28555938601493835\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Device configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define paths and directories\n",
    "dataset_path = \"./PlantDoc-dataset/train\"\n",
    "disease_directories = [\"Apple rust leaf\", \"Bell_pepper leaf spot\", \"Corn rust leaf\"]\n",
    "\n",
    "# Annotation data for creating CSV\n",
    "annotations = [\n",
    "    {\n",
    "        \"filename\": \"Apple rust leaf/Apple rust leaf (2).jpg\",\n",
    "        \"disease\": \"Apple Rust Leaf\",\n",
    "        \"symptoms\": \"Yellow-orange spots, premature leaf fall\",\n",
    "        \"treatment\": \"Use fungicide containing myclobutanil\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"Bell_pepper leaf spot/Bell_pepper leaf spot (3).jpg\",\n",
    "        \"disease\": \"Bell Pepper Leaf Spot\",\n",
    "        \"symptoms\": \"Dark, water-soaked spots on leaves\",\n",
    "        \"treatment\": \"Apply copper-based fungicide\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"Corn rust leaf/Corn rust leaf (5).jpg\",\n",
    "        \"disease\": \"Corn Rust Leaf\",\n",
    "        \"symptoms\": \"Reddish-brown pustules, leaf wilting\",\n",
    "        \"treatment\": \"Use resistant corn varieties and fungicides\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create CSV from annotations\n",
    "annotations_df = pd.DataFrame(annotations)\n",
    "annotations_df.to_csv(\"disease_annotations.csv\", index=False)\n",
    "\n",
    "# Create dictionary for symptoms and treatments\n",
    "disease_info = {\n",
    "    \"Apple Rust Leaf\": {\n",
    "        \"symptoms\": \"Yellow-orange spots, premature leaf fall\",\n",
    "        \"treatment\": \"Use fungicide containing myclobutanil\"\n",
    "    },\n",
    "    \"Bell Pepper Leaf Spot\": {\n",
    "        \"symptoms\": \"Dark, water-soaked spots on leaves\",\n",
    "        \"treatment\": \"Apply copper-based fungicide\"\n",
    "    },\n",
    "    \"Corn Rust Leaf\": {\n",
    "        \"symptoms\": \"Reddish-brown pustules, leaf wilting\",\n",
    "        \"treatment\": \"Use resistant corn varieties and fungicides\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define custom dataset class\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, disease_dirs, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        # Loop over disease directories\n",
    "        for idx, disease_dir in enumerate(disease_dirs):\n",
    "            disease_path = os.path.join(root_dir, disease_dir)\n",
    "            for img_name in os.listdir(disease_path):\n",
    "                img_path = os.path.join(disease_path, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)  # Assign a numeric label for each disease\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "dataset = PlantDiseaseDataset(dataset_path, disease_directories, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "num_classes = len(disease_directories)\n",
    "cnn_model = SimpleCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (only 2 epochs for demonstration)\n",
    "for epoch in range(2):\n",
    "    cnn_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/2], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(cnn_model.state_dict(), \"plant_disease_cnn.pth\")\n",
    "\n",
    "# Load CLIP model and processor for integration\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Function to encode images using CLIP\n",
    "def encode_image_with_clip(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.get_image_features(**inputs)\n",
    "    return image_features\n",
    "\n",
    "# Function to encode text using CLIP\n",
    "def encode_text_with_clip(text):\n",
    "    inputs = clip_processor(text=text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = clip_model.get_text_features(**inputs)\n",
    "    return text_features\n",
    "\n",
    "# Function to integrate CNN and CLIP\n",
    "def integrated_diagnosis(image_path, text_query):\n",
    "    # Use CNN to classify image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    cnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        cnn_output = cnn_model(image_tensor)\n",
    "        _, predicted_class = torch.max(cnn_output, 1)\n",
    "        disease_name = disease_directories[predicted_class.item()]\n",
    "\n",
    "    # Fetch symptoms and treatment\n",
    "    disease_key = disease_name.replace(\"_\", \" \").title()\n",
    "    symptoms = disease_info[disease_key][\"symptoms\"]\n",
    "    treatment = disease_info[disease_key][\"treatment\"]\n",
    "    print(f\"CNN Prediction: {disease_name}\")\n",
    "    print(f\"Symptoms: {symptoms}\")\n",
    "    print(f\"Treatment: {treatment}\")\n",
    "    \n",
    "    # Use CLIP to enhance diagnosis\n",
    "    image_features = encode_image_with_clip(image_path)\n",
    "    text_features = encode_text_with_clip(text_query)\n",
    "    similarity = torch.nn.functional.cosine_similarity(image_features, text_features, dim=1).item()\n",
    "    print(f\"CLIP Similarity with Query: {similarity}\")\n",
    "\n",
    "# Example usage\n",
    "integrated_diagnosis(\"./PlantDoc-dataset/train/Apple rust leaf/Apple rust leaf (13).jpg\", \"How to treat yellowing spots on apple leaves?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001c38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512843f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c6aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.5983\n",
      "Epoch [2/15], Loss: 0.0113\n",
      "Epoch [3/15], Loss: 0.0824\n",
      "Epoch [4/15], Loss: 0.0686\n",
      "Epoch [5/15], Loss: 0.1040\n",
      "Epoch [6/15], Loss: 0.0102\n",
      "Epoch [7/15], Loss: 0.3106\n",
      "Epoch [8/15], Loss: 0.0401\n",
      "Epoch [9/15], Loss: 0.0048\n",
      "Epoch [10/15], Loss: 0.0041\n",
      "Epoch [11/15], Loss: 0.1992\n",
      "Epoch [12/15], Loss: 0.0043\n",
      "Epoch [13/15], Loss: 0.0855\n",
      "Epoch [14/15], Loss: 0.0014\n",
      "Epoch [15/15], Loss: 0.0255\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define fine-tuning parameters directly in the Python code\n",
    "config = {\n",
    "    \"epochs\": 15,\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"clip_lr\": 0.00005,\n",
    "    \"cnn_model\": \"resnet18\",\n",
    "    \"fine_tune_layers\": [\"layer4\", \"fc\"]\n",
    "}\n",
    "\n",
    "# Device configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define paths and directories\n",
    "dataset_path = \"./PlantDoc-dataset/train\"\n",
    "disease_directories = [\"Apple rust leaf\", \"Bell_pepper leaf spot\", \"Corn rust leaf\"]\n",
    "\n",
    "# Annotation data for creating CSV\n",
    "annotations = [\n",
    "    {\n",
    "        \"filename\": \"Apple rust leaf/Apple rust leaf (2).jpg\",\n",
    "        \"disease\": \"Apple Rust Leaf\",\n",
    "        \"symptoms\": \"Yellow-orange spots, premature leaf fall\",\n",
    "        \"treatment\": \"Use fungicide containing myclobutanil\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"Bell_pepper leaf spot/Bell_pepper leaf spot (3).jpg\",\n",
    "        \"disease\": \"Bell Pepper Leaf Spot\",\n",
    "        \"symptoms\": \"Dark, water-soaked spots on leaves\",\n",
    "        \"treatment\": \"Apply copper-based fungicide\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"Corn rust leaf/Corn rust leaf (5).jpg\",\n",
    "        \"disease\": \"Corn Rust Leaf\",\n",
    "        \"symptoms\": \"Reddish-brown pustules, leaf wilting\",\n",
    "        \"treatment\": \"Use resistant corn varieties and fungicides\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create CSV from annotations\n",
    "annotations_df = pd.DataFrame(annotations)\n",
    "annotations_df.to_csv(\"disease_annotations.csv\", index=False)\n",
    "\n",
    "# Create dictionary for symptoms and treatments\n",
    "disease_info = {\n",
    "    \"Apple Rust Leaf\": {\n",
    "        \"symptoms\": \"Yellow-orange spots, premature leaf fall\",\n",
    "        \"treatment\": \"Use fungicide containing myclobutanil\"\n",
    "    },\n",
    "    \"Bell Pepper Leaf Spot\": {\n",
    "        \"symptoms\": \"Dark, water-soaked spots on leaves\",\n",
    "        \"treatment\": \"Apply copper-based fungicide\"\n",
    "    },\n",
    "    \"Corn Rust Leaf\": {\n",
    "        \"symptoms\": \"Reddish-brown pustules, leaf wilting\",\n",
    "        \"treatment\": \"Use resistant corn varieties and fungicides\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define custom dataset class\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, disease_dirs, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        # Loop over disease directories\n",
    "        for idx, disease_dir in enumerate(disease_dirs):\n",
    "            disease_path = os.path.join(root_dir, disease_dir)\n",
    "            for img_name in os.listdir(disease_path):\n",
    "                img_path = os.path.join(disease_path, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)  # Assign a numeric label for each disease\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "dataset = PlantDiseaseDataset(dataset_path, disease_directories, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        # Freeze all layers except specified layers for fine-tuning\n",
    "        for name, param in self.model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            if any(layer in name for layer in config[\"fine_tune_layers\"]):\n",
    "                param.requires_grad = True\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "num_classes = len(disease_directories)\n",
    "cnn_model = SimpleCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "# Training loop with fine-tuning\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    cnn_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{config['epochs']}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(cnn_model.state_dict(), \"plant_disease_cnn_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd740c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9199\n",
      "Epoch [2/10], Loss: 0.4417\n",
      "Epoch [3/10], Loss: 0.2912\n",
      "Epoch [4/10], Loss: 1.3282\n",
      "Epoch [5/10], Loss: 0.1439\n",
      "Epoch [6/10], Loss: 0.1904\n",
      "Epoch [7/10], Loss: 0.3712\n",
      "Epoch [8/10], Loss: 0.5786\n",
      "Epoch [9/10], Loss: 0.5023\n",
      "Epoch [10/10], Loss: 0.1858\n",
      "CNN Prediction: Apple rust leaf\n",
      "Symptoms: Yellow-orange spots, premature leaf fall\n",
      "Treatment: Use fungicide containing myclobutanil\n",
      "CLIP Similarity with Query: 0.28555938601493835\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# JSON configuration (embedded directly within the code)\n",
    "config_json = \"\"\"\n",
    "{\n",
    "    \"device\": \"cuda\",\n",
    "    \"dataset_path\": \"./PlantDoc-dataset/train\",\n",
    "    \"disease_directories\": [\"Apple rust leaf\", \"Bell_pepper leaf spot\", \"Corn rust leaf\"],\n",
    "    \"annotations\": [\n",
    "        {\n",
    "            \"filename\": \"Apple rust leaf\",\n",
    "            \"disease\": \"Apple Rust Leaf\",\n",
    "            \"symptoms\": \"Yellow-orange spots, premature leaf fall\",\n",
    "            \"treatment\": \"Use fungicide containing myclobutanil\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"Bell_pepper leaf spot\",\n",
    "            \"disease\": \"Bell Pepper Leaf Spot\",\n",
    "            \"symptoms\": \"Dark, water-soaked spots on leaves\",\n",
    "            \"treatment\": \"Apply copper-based fungicide\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"Corn rust leaf\",\n",
    "            \"disease\": \"Corn Rust Leaf\",\n",
    "            \"symptoms\": \"Reddish-brown pustules, leaf wilting\",\n",
    "            \"treatment\": \"Use resistant corn varieties and fungicides\"\n",
    "        }\n",
    "    ],\n",
    "    \"train_batch_size\": 8,\n",
    "    \"num_epochs\": 10,\n",
    "    \"learning_rate\": 0.001\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Parse JSON configuration\n",
    "config = json.loads(config_json)\n",
    "device = config[\"device\"] if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_path = config[\"dataset_path\"]\n",
    "disease_directories = config[\"disease_directories\"]\n",
    "\n",
    "# Create CSV from annotations\n",
    "annotations_df = pd.DataFrame(config[\"annotations\"])\n",
    "annotations_df.to_csv(\"disease_annotations.csv\", index=False)\n",
    "\n",
    "# Create dictionary for symptoms and treatments\n",
    "disease_info = {\n",
    "    annotation[\"disease\"]: {\n",
    "        \"symptoms\": annotation[\"symptoms\"],\n",
    "        \"treatment\": annotation[\"treatment\"]\n",
    "    }\n",
    "    for annotation in config[\"annotations\"]\n",
    "}\n",
    "\n",
    "# Define custom dataset class\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, disease_dirs, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        # Loop over disease directories\n",
    "        for idx, disease_dir in enumerate(disease_dirs):\n",
    "            disease_path = os.path.join(root_dir, disease_dir)\n",
    "            for img_name in os.listdir(disease_path):\n",
    "                img_path = os.path.join(disease_path, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)  # Assign a numeric label for each disease\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "dataset = PlantDiseaseDataset(dataset_path, disease_directories, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=config[\"train_batch_size\"], shuffle=True)\n",
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "num_classes = len(disease_directories)\n",
    "cnn_model = SimpleCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "# Training loop (configurable number of epochs)\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    cnn_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch + 1}/{config['num_epochs']}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(cnn_model.state_dict(), \"plant_disease_cnn.pth\")\n",
    "\n",
    "# Load CLIP model and processor for integration\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Function to encode images using CLIP\n",
    "def encode_image_with_clip(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.get_image_features(**inputs)\n",
    "    return image_features\n",
    "\n",
    "# Function to encode text using CLIP\n",
    "def encode_text_with_clip(text):\n",
    "    inputs = clip_processor(text=text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = clip_model.get_text_features(**inputs)\n",
    "    return text_features\n",
    "\n",
    "# Function to integrate CNN and CLIP\n",
    "def integrated_diagnosis(image_path, text_query):\n",
    "    # Use CNN to classify image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    cnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        cnn_output = cnn_model(image_tensor)\n",
    "        _, predicted_class = torch.max(cnn_output, 1)\n",
    "        disease_name = disease_directories[predicted_class.item()]\n",
    "    \n",
    "    # Fetch symptoms and treatment\n",
    "    disease_key = disease_name.replace(\"_\", \" \").title()\n",
    "    symptoms = disease_info[disease_key][\"symptoms\"]\n",
    "    treatment = disease_info[disease_key][\"treatment\"]\n",
    "    print(f\"CNN Prediction: {disease_name}\")\n",
    "    print(f\"Symptoms: {symptoms}\")\n",
    "    print(f\"Treatment: {treatment}\")\n",
    "\n",
    "    # Use CLIP to enhance diagnosis\n",
    "    image_features = encode_image_with_clip(image_path)\n",
    "    text_features = encode_text_with_clip(text_query)\n",
    "    similarity = torch.nn.functional.cosine_similarity(image_features, text_features, dim=1).item()\n",
    "    print(f\"CLIP Similarity with Query: {similarity}\")\n",
    "\n",
    "# Example usage\n",
    "integrated_diagnosis(\"./PlantDoc-dataset/train/Apple rust leaf/Apple rust leaf (13).jpg\", \"How to treat yellowing spots on apple leaves?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e5b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jjj\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1598, Training Accuracy: 60.73%, Validation Accuracy: 60.73%\n",
      "Epoch [2/10], Loss: 0.4354, Training Accuracy: 66.80%, Validation Accuracy: 66.80%\n",
      "Epoch [3/10], Loss: 0.6718, Training Accuracy: 92.71%, Validation Accuracy: 92.71%\n",
      "Epoch [4/10], Loss: 0.5094, Training Accuracy: 81.38%, Validation Accuracy: 81.38%\n",
      "Epoch [5/10], Loss: 0.7085, Training Accuracy: 85.83%, Validation Accuracy: 85.83%\n",
      "Epoch [6/10], Loss: 0.0596, Training Accuracy: 85.43%, Validation Accuracy: 85.43%\n",
      "Epoch [7/10], Loss: 0.1723, Training Accuracy: 93.93%, Validation Accuracy: 93.93%\n",
      "Epoch [8/10], Loss: 1.3988, Training Accuracy: 83.40%, Validation Accuracy: 83.40%\n",
      "Epoch [9/10], Loss: 0.1616, Training Accuracy: 87.45%, Validation Accuracy: 87.45%\n",
      "Epoch [10/10], Loss: 0.2520, Training Accuracy: 95.14%, Validation Accuracy: 95.14%\n",
      "CNN Prediction: Apple rust leaf\n",
      "Symptoms: Yellow-orange spots, premature leaf fall\n",
      "Treatment: Use fungicide containing myclobutanil\n",
      "CLIP Similarity with Query: 0.28555938601493835\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# JSON configuration (embedded directly within the code)\n",
    "config_json = \"\"\"\n",
    "{\n",
    "    \"device\": \"cuda\",\n",
    "    \"dataset_path\": \"./PlantDoc-dataset/train\",\n",
    "    \"disease_directories\": [\"Apple rust leaf\", \"Bell_pepper leaf spot\", \"Corn rust leaf\"],\n",
    "    \"annotations\": [\n",
    "        {\n",
    "            \"filename\": \"Apple rust leaf\",\n",
    "            \"disease\": \"Apple Rust Leaf\",\n",
    "            \"symptoms\": \"Yellow-orange spots, premature leaf fall\",\n",
    "            \"treatment\": \"Use fungicide containing myclobutanil\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"Bell_pepper leaf spot\",\n",
    "            \"disease\": \"Bell Pepper Leaf Spot\",\n",
    "            \"symptoms\": \"Dark, water-soaked spots on leaves\",\n",
    "            \"treatment\": \"Apply copper-based fungicide\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"Corn rust leaf\",\n",
    "            \"disease\": \"Corn Rust Leaf\",\n",
    "            \"symptoms\": \"Reddish-brown pustules, leaf wilting\",\n",
    "            \"treatment\": \"Use resistant corn varieties and fungicides\"\n",
    "        }\n",
    "    ],\n",
    "    \"train_batch_size\": 8,\n",
    "    \"num_epochs\": 10,\n",
    "    \"learning_rate\": 0.001\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Parse JSON configuration\n",
    "config = json.loads(config_json)\n",
    "device = config[\"device\"] if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_path = config[\"dataset_path\"]\n",
    "disease_directories = config[\"disease_directories\"]\n",
    "\n",
    "# Create CSV from annotations\n",
    "annotations_df = pd.DataFrame(config[\"annotations\"])\n",
    "annotations_df.to_csv(\"disease_annotations.csv\", index=False)\n",
    "\n",
    "# Create dictionary for symptoms and treatments\n",
    "disease_info = {\n",
    "    annotation[\"disease\"]: {\n",
    "        \"symptoms\": annotation[\"symptoms\"],\n",
    "        \"treatment\": annotation[\"treatment\"]\n",
    "    }\n",
    "    for annotation in config[\"annotations\"]\n",
    "}\n",
    "\n",
    "# Define custom dataset class\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, disease_dirs, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        # Loop over disease directories\n",
    "        for idx, disease_dir in enumerate(disease_dirs):\n",
    "            disease_path = os.path.join(root_dir, disease_dir)\n",
    "            for img_name in os.listdir(disease_path):\n",
    "                img_path = os.path.join(disease_path, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)  # Assign a numeric label for each disease\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize dataset and split into train/validation sets\n",
    "dataset = PlantDiseaseDataset(dataset_path, disease_directories, transform=transform)\n",
    "train_paths, val_paths = train_test_split(dataset.image_paths, test_size=0.2, random_state=42)\n",
    "train_dataset = PlantDiseaseDataset(dataset_path, disease_directories, transform=transform)\n",
    "val_dataset = PlantDiseaseDataset(dataset_path, disease_directories, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"train_batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"train_batch_size\"], shuffle=False)\n",
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "num_classes = len(disease_directories)\n",
    "cnn_model = SimpleCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total * 100\n",
    "    return accuracy\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    cnn_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # After each epoch, calculate the training accuracy\n",
    "    train_accuracy = calculate_accuracy(cnn_model, train_loader)\n",
    "    val_accuracy = calculate_accuracy(cnn_model, val_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{config['num_epochs']}], Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(cnn_model.state_dict(), \"plant_disease_cnn.pth\")\n",
    "\n",
    "# Load CLIP model and processor for integration\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Function to encode images using CLIP\n",
    "def encode_image_with_clip(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.get_image_features(**inputs)\n",
    "    return image_features\n",
    "\n",
    "# Function to encode text using CLIP\n",
    "def encode_text_with_clip(text):\n",
    "    inputs = clip_processor(text=text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = clip_model.get_text_features(**inputs)\n",
    "    return text_features\n",
    "\n",
    "# Function to integrate CNN and CLIP\n",
    "def integrated_diagnosis(image_path, text_query):\n",
    "    # Use CNN to classify image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    cnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        cnn_output = cnn_model(image_tensor)\n",
    "        _, predicted_class = torch.max(cnn_output, 1)\n",
    "        disease_name = disease_directories[predicted_class.item()]\n",
    "        # Fetch symptoms and treatment\n",
    "    disease_key = disease_name.replace(\"_\", \" \").title()\n",
    "    symptoms = disease_info[disease_key][\"symptoms\"]\n",
    "    treatment = disease_info[disease_key][\"treatment\"]\n",
    "    print(f\"CNN Prediction: {disease_name}\")\n",
    "    print(f\"Symptoms: {symptoms}\")\n",
    "    print(f\"Treatment: {treatment}\")\n",
    "    # Use CLIP to enhance diagnosis\n",
    "    image_features = encode_image_with_clip(image_path)\n",
    "    text_features = encode_text_with_clip(text_query)\n",
    "    similarity = torch.nn.functional.cosine_similarity(image_features, text_features, dim=1).item()\n",
    "    print(f\"CLIP Similarity with Query: {similarity}\")\n",
    "\n",
    "# query 1\n",
    "integrated_diagnosis(\"./PlantDoc-dataset/train/Apple rust leaf/Apple rust leaf (13).jpg\", \n",
    "                     \"How to treat yellowing spots on apple leaves?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b83615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Prediction: Bell_pepper leaf spot\n",
      "Symptoms: Dark, water-soaked spots on leaves\n",
      "Treatment: Apply copper-based fungicide\n",
      "CLIP Similarity with Query: 0.281999796628952\n"
     ]
    }
   ],
   "source": [
    "# query 2\n",
    "\n",
    "integrated_diagnosis(\"./PlantDoc-dataset/train/Bell_pepper leaf spot/Bell_pepper leaf spot (7).jpg\", \n",
    "                     \"what are the dark spots on the leaves?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "700a9c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Prediction: Corn rust leaf\n",
      "Symptoms: Reddish-brown pustules, leaf wilting\n",
      "Treatment: Use resistant corn varieties and fungicides\n",
      "CLIP Similarity with Query: 0.2102934718132019\n"
     ]
    }
   ],
   "source": [
    "# query 3\n",
    "\n",
    "integrated_diagnosis(\"./PlantDoc-dataset/train/Corn rust leaf/Corn rust leaf (6).jpg\", \n",
    "                     \"why is that reddish brown color?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107406e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Prediction: Corn rust leaf\n",
      "Symptoms: Reddish-brown pustules, leaf wilting\n",
      "Treatment: Use resistant corn varieties and fungicides\n",
      "CLIP Similarity with Query: 0.23080112040042877\n"
     ]
    }
   ],
   "source": [
    "# query 4\n",
    "\n",
    "integrated_diagnosis(\"./PlantDoc-dataset/train/Corn rust leaf/Corn rust leaf (6).jpg\", \n",
    "                     \"how to treat this leaf wilting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06060ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
